{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prediction(trained_model = None, dataset = None):\n",
    "    X_test_Mon = dataset['X_test_Mon'].astype('float32')\n",
    "    X_test_Unmon = dataset['X_test_Unmon'].astype('float32')\n",
    "    X_test_Mon = X_test_Mon[:, :, np.newaxis]\n",
    "    X_test_Unmon = X_test_Unmon[:, :, np.newaxis]\n",
    "    result_Mon = trained_model.predict(X_test_Mon, verbose=2)\n",
    "    result_Unmon = trained_model.predict(X_test_Unmon, verbose=2)\n",
    "    return result_Mon, result_Unmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluation(threshold_val = None, monitored_label = None,\n",
    "                   unmonitored_label = None, result_Mon = None,\n",
    "                   result_Unmon = None, log_file = None):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    \n",
    "    for i in range(len(result_Mon)):\n",
    "        sm_vector = result_Mon[i]\n",
    "        predicted_class = np.argmax(sm_vector)\n",
    "        max_prob = max(sm_vector)\n",
    "\n",
    "        if predicted_class in monitored_label:\n",
    "            if max_prob >= threshold_val: \n",
    "                TP = TP + 1\n",
    "            else:\n",
    "                FN = FN + 1\n",
    "        elif predicted_class in unmonitored_label: \n",
    "            FN = FN + 1\n",
    "\n",
    "    for i in range(len(result_Unmon)):\n",
    "        sm_vector = result_Unmon[i]\n",
    "        predicted_class = np.argmax(sm_vector)\n",
    "        max_prob = max(sm_vector)\n",
    "\n",
    "        if predicted_class in monitored_label: \n",
    "            if max_prob >= threshold_val: \n",
    "                FP = FP + 1\n",
    "            else: \n",
    "                TN = TN + 1\n",
    "        elif predicted_class in unmonitored_label:\n",
    "            TN = TN + 1\n",
    "\n",
    "   \n",
    "    TPR = float(TP) / (TP + FN)\n",
    "    FPR = float(FP) / (FP + TN)\n",
    "    Precision = float(TP) / (TP + FP)\n",
    "    Recall = float(TP) / (TP + FN)\n",
    "    log_file.writelines(\"%.6f,%d,%d,%d,%d,%.6f,%.6f,%.6f,%.6f\\n\"%(threshold_val, TP, FP, TN, FN, TPR, FPR, Precision, Recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OW_Evaluation():\n",
    "    evaluation_type = 'OpenWorld_NoDef'\n",
    "    threshold = 1.0 - 1 / np.logspace(0.05, 2, num=15, endpoint=True)\n",
    "    file_name = './results/%s.csv'%evaluation_type\n",
    "    log_file =  open(file_name, \"w\")\n",
    "    dataset = {}\n",
    "    model_name = ''\n",
    "    from Datareader import LoadDataNoDefOW_Evaluation\n",
    "    X_test_Mon, y_test_Mon, X_test_Unmon, y_test_Unmon = LoadDataNoDefOW_Evaluation()\n",
    "    model_name = './saved_trained_models/OpenWorld_NoDef.h5'\n",
    "\n",
    "    dataset['X_test_Mon'] = X_test_Mon\n",
    "    dataset['y_test_Mon'] = y_test_Mon\n",
    "    dataset['X_test_Unmon'] = X_test_Unmon\n",
    "    dataset['y_test_Unmon'] = y_test_Unmon\n",
    "\n",
    "    trained_model = load_model(model_name)\n",
    "    result_Mon, result_Unmon = Prediction(trained_model = trained_model, dataset = dataset)\n",
    "    monitored_label = list(y_test_Mon)\n",
    "    unmonitored_label = list(y_test_Unmon)\n",
    "    \n",
    "    \n",
    "    log_file.writelines(\"%s,%s,%s,%s,%s,%s  ,%s  ,  %s, %s\\n\" % ('Threshold', 'TP', 'FP', 'TN', 'FN', 'TPR', 'FPR', 'Precision', 'Recall'))\n",
    "    for th in threshold:\n",
    "        Evaluation(threshold_val = th, monitored_label = monitored_label,\n",
    "                   unmonitored_label = unmonitored_label, result_Mon = result_Mon,\n",
    "                   result_Unmon = result_Unmon, log_file = log_file)\n",
    "    log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OW_Evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
